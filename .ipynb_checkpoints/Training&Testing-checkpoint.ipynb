{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the preprocessed dataset\n",
    "\n",
    "import json\n",
    "\n",
    "jsonFile=json.load(open(\"preprocessed_dataset.json\"))\n",
    "class_label=[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "clean_text= jsonFile[\"clean_text\"]\n",
    "result= jsonFile[\"result\"]\n",
    "\n",
    "for i in clean_text:\n",
    "    i+= [-1]* (2041- len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mapreduce-py in c:\\users\\johnconda\\lib\\site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "# mapreduce-py installation (for using mapreduce within python)\n",
    "\n",
    "!pip install mapreduce-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping text to numerical values\n",
    "\n",
    "# def map_text():\n",
    "x_dict={}\n",
    "y_dict={}\n",
    "hash_val={}\n",
    "\n",
    "x_val=0\n",
    "y_val=0\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# mapping and transforming text to numerical values\n",
    "for i in range(len(clean_text)):\n",
    "    store=[]\n",
    "    for j in clean_text[i]:\n",
    "        if j in x_dict:\n",
    "            store.append(x_dict[j])\n",
    "        else:\n",
    "            x_dict[j]=x_val\n",
    "            x_val+=1\n",
    "            store.append(x_dict[j])\n",
    "    X.append(store)\n",
    "\n",
    "    s=''.join([str(x) for x in result[i]])\n",
    "    if s in y_dict:\n",
    "        Y.append(y_dict[s])\n",
    "    else:\n",
    "        y_dict[s]=y_val\n",
    "        hash_val[y_val]=s\n",
    "        y_val+=1\n",
    "        Y.append(y_dict[s])\n",
    "#     return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "def train(X,Y):\n",
    "    arr=[]\n",
    "    for i in X:\n",
    "       i+= [-1]* (2041- len(i))\n",
    "\n",
    "    from sklearn import tree\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X, Y)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, clf):\n",
    "    x=clf.predict(X)\n",
    "    test_set= X[0:int((0.2)*len(X))]\n",
    "    x=clf.predict(X)\n",
    "\n",
    "    labels = result[0:int((0.2)*len(X))]\n",
    "    predictions = x\n",
    "    from sklearn.metrics import precision_score\n",
    "\n",
    "#     p=precision_score(labels, x, average='micro')\n",
    "#     r=recall_score(labels, x, average='micro')\n",
    "#     a=accuracy_score(labels, x, average='micro')\n",
    "    \n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR Result  : (0.9993836671802774, 0.9893898305084745, 0.9793959938366719)\n",
      "accuracy: 0.9993836671802774\n",
      "precision: 0.9893898305084745\n",
      "recall: 0.9793959938366719\n",
      "F1 Score: 0.9843675471048782\n"
     ]
    }
   ],
   "source": [
    "# training and testing decision tree\n",
    "\n",
    "from mapreduce import *\n",
    "\n",
    "MR=MapReducer().prefilter(map_text).mapper(train).reducer(test, None)\n",
    "res = MR(range(len(MR)))\n",
    "print('MR Result  :', res)\n",
    "\n",
    "accuracy, precision, recall=res\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)\n",
    "\n",
    "print(\"F1 Score:\", ((2*precision*recall)/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm \n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def train():\n",
    "    from sklearn.svm import SVC\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    clf.fit(X, Y)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.94144838212635\n",
      "precision: 86.39671802773499\n",
      "recall: 93.04261941448384\n",
      "F1 Score: 89.59659647320666\n"
     ]
    }
   ],
   "source": [
    "# training and testing svm\n",
    "\n",
    "from mapreduce import *\n",
    "\n",
    "MR=MapReducer().prefilter(map_text).mapper(train).reducer(test, None)\n",
    "res = MR(range(len(MR)))\n",
    "\n",
    "accuracy, precision, recall=res\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)\n",
    "\n",
    "print(\"F1 Score:\", ((2*precision*recall)/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  3  1  3  4  1  1  5  3  1  3  1  1 10  1  3  1  3  0  1  1]\n"
     ]
    }
   ],
   "source": [
    "# prediction with sample reddit data\n",
    "\n",
    "# fetching reddit data\n",
    "import http.client\n",
    "\n",
    "conn = http.client.HTTPSConnection(\"reddit3.p.rapidapi.com\")\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"reddit3.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"52e70ee3a0mshe32a5a1bbaa67bcp1e2257jsndfce50b84406\"\n",
    "    }\n",
    "\n",
    "conn.request(\"GET\", \"/all?url=https%3A%2F%2Fwww.reddit.com%2Fr%all\", headers=headers)\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "text_data=data[\"replies\"]\n",
    "text_data=text_data[0:min(20, len(text_data))]\n",
    "\n",
    "\n",
    "# predicting\n",
    "\n",
    "res= test(text_data, train(X,Y))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02\n",
      "toxic obscene \n",
      "024\n",
      "toxic obscene insult \n",
      "0\n",
      "toxic \n",
      "024\n",
      "toxic obscene insult \n",
      "02\n",
      "toxic obscene \n",
      "0\n",
      "toxic \n",
      "0\n",
      "toxic \n",
      "03\n",
      "toxic threat \n",
      "024\n",
      "toxic obscene insult \n",
      "0\n",
      "toxic \n",
      "024\n",
      "toxic obscene insult \n",
      "0\n",
      "toxic \n",
      "0\n",
      "toxic \n",
      "012\n",
      "toxic severe_toxic obscene \n",
      "0\n",
      "toxic \n",
      "024\n",
      "toxic obscene insult \n",
      "0\n",
      "toxic \n",
      "024\n",
      "toxic obscene insult \n",
      "0124\n",
      "toxic severe_toxic obscene insult \n",
      "0\n",
      "toxic \n",
      "0\n",
      "toxic \n"
     ]
    }
   ],
   "source": [
    "# printing hash values of the results\n",
    "\n",
    "for i in res:\n",
    "    print(hash_val[i])\n",
    "    r=\"\"\n",
    "    for j in hash_val[i]:\n",
    "        r+=class_label[int(j)]\n",
    "        r+=' '\n",
    "    print(r)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
